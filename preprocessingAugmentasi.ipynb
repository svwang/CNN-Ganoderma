{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6857fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "import json\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67376bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Dataset Loader\n",
    "# =====================\n",
    "IMG_SIZE = 224\n",
    "BATCH = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"dataset_classification/train\",\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH,\n",
    "    label_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"dataset_classification/valid\",\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH,\n",
    "    label_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(\"Classes:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc34a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_from_dataset(dataset, num_batches=1):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i, (img_batch, label_batch) in enumerate(dataset):\n",
    "        images.append(img_batch.numpy())\n",
    "        labels.append(label_batch.numpy())\n",
    "        if i+1 >= num_batches:\n",
    "            break\n",
    "    images = np.concatenate(images, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return images, labels\n",
    "\n",
    "# Ambil 1 batch saja untuk contoh\n",
    "images, labels = get_images_from_dataset(train_ds, num_batches=1)\n",
    "print(\"Shape images:\", images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97058db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Normalisasi Min-Max\n",
    "# =====================\n",
    "min_val = images.min()\n",
    "max_val = images.max()\n",
    "images_minmax = (images - min_val) / (max_val - min_val)\n",
    "print(\"Min-Max -> min:\", images_minmax.min(), \"max:\", images_minmax.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cfd23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Normalisasi Z-Score\n",
    "# =====================\n",
    "mean_val = images.mean()\n",
    "std_val = images.std()\n",
    "images_zscore = (images - mean_val) / std_val\n",
    "print(\"Z-Score -> mean:\", images_zscore.mean(), \"std:\", images_zscore.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7dfe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Visualisasi beberapa gambar\n",
    "# =====================\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "for i in range(5):\n",
    "    # Gambar asli\n",
    "    axes[0, i].imshow(images[i].astype(np.uint8))\n",
    "    axes[0, i].set_title(\"Original\")\n",
    "    axes[0, i].axis(\"off\")\n",
    "\n",
    "    # Gambar Min-Max\n",
    "    axes[1, i].imshow(images_minmax[i])\n",
    "    axes[1, i].set_title(\"Min-Max\")\n",
    "    axes[1, i].axis(\"off\")\n",
    "\n",
    "    # Gambar Z-Score (dikembalikan ke range 0-1 untuk visualisasi)\n",
    "    z_img = (images_zscore[i] - images_zscore[i].min()) / (images_zscore[i].max() - images_zscore[i].min())\n",
    "    axes[2, i].imshow(z_img)\n",
    "    axes[2, i].set_title(\"Z-Score\")\n",
    "    axes[2, i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d039b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Visualisasi histogram distribusi pixel\n",
    "# =====================\n",
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "# Histogram Original\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(images.flatten(), bins=50, color='blue', alpha=0.7)\n",
    "plt.title(\"Original Pixel Distribution\")\n",
    "plt.xlabel(\"Pixel Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Histogram Min-Max\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(images_minmax.flatten(), bins=50, color='green', alpha=0.7)\n",
    "plt.title(\"Min-Max Normalized Distribution\")\n",
    "plt.xlabel(\"Pixel Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Histogram Z-Score\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(images_zscore.flatten(), bins=50, color='red', alpha=0.7)\n",
    "plt.title(\"Z-Score Normalized Distribution\")\n",
    "plt.xlabel(\"Pixel Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057cc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Augmentasi Pipeline\n",
    "# =====================\n",
    "data_aug = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomBrightness(0.2),\n",
    "], name=\"augment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5560e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder untuk simpan hasil augmentasi\n",
    "SAVE_DIR = \"augmented_output\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "annotations = []\n",
    "\n",
    "# load semua dataset\n",
    "for images, labels in train_ds:\n",
    "    aug_imgs = data_aug(images, training=True).numpy()\n",
    "    images = images.numpy().astype(np.uint8)\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        class_idx = np.argmax(labels[i].numpy())\n",
    "        class_name = class_names[class_idx]\n",
    "\n",
    "        # Simpan gambar asli\n",
    "        orig_filename = f\"orig_{len(annotations)}_{class_name}.png\"\n",
    "        orig_path = os.path.join(SAVE_DIR, orig_filename)\n",
    "        Image.fromarray(images[i]).save(orig_path)\n",
    "\n",
    "        # Simpan gambar augmentasi\n",
    "        aug_filename = f\"aug_{len(annotations)}_{class_name}.png\"\n",
    "        aug_path = os.path.join(SAVE_DIR, aug_filename)\n",
    "        Image.fromarray(aug_imgs[i].astype(np.uint8)).save(aug_path)\n",
    "\n",
    "        # Tambahkan ke anotasi JSON\n",
    "        annotations.append({\n",
    "            \"class\": class_name,\n",
    "            \"original\": orig_path,\n",
    "            \"augmented\": aug_path\n",
    "        })\n",
    "\n",
    "# Simpan JSON anotasi\n",
    "json_path = os.path.join(SAVE_DIR, \"annotations.json\")\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump(annotations, f, indent=4)\n",
    "\n",
    "print(f\"Anotasi augmentasi disimpan di: {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb8dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# Hitung jumlah gambar per kelas\n",
    "orig_counts = collections.Counter([ann[\"class\"] for ann in annotations])\n",
    "aug_counts = collections.Counter([ann[\"class\"] for ann in annotations])\n",
    "\n",
    "# Karena setiap gambar ada pasangan (original + augmented),\n",
    "# kita perlu hitung yang asli saja\n",
    "total_per_class = {cls: orig_counts[cls]//2 for cls in class_names}\n",
    "aug_per_class = {cls: total_per_class[cls] for cls in class_names}\n",
    "\n",
    "print(\"\\n=== Statistik Augmentasi ===\")\n",
    "for cls in class_names:\n",
    "    print(f\"Kelas {cls}: Original={total_per_class[cls]}, Augmented={aug_per_class[cls]}\")\n",
    "\n",
    "total_orig = sum(total_per_class.values())\n",
    "total_aug = sum(aug_per_class.values())\n",
    "print(f\"\\nTotal Original : {total_orig}\")\n",
    "print(f\"Total Augmented: {total_aug}\")\n",
    "print(f\"Total Semua    : {total_orig + total_aug}\")\n",
    "\n",
    "# =====================\n",
    "# Visualisasi Bar Chart\n",
    "# =====================\n",
    "x = np.arange(len(class_names))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(x - width/2, [total_per_class[cls] for cls in class_names], width, label=\"Original\")\n",
    "plt.bar(x + width/2, [aug_per_class[cls] for cls in class_names], width, label=\"Augmented\")\n",
    "\n",
    "plt.xticks(x, class_names, rotation=45)\n",
    "plt.ylabel(\"Jumlah Gambar\")\n",
    "plt.title(\"Distribusi Original vs Augmented per Kelas\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =====================\n",
    "# Visualisasi Pie Chart\n",
    "# =====================\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.pie([total_orig, total_aug],\n",
    "        labels=[\"Original\", \"Augmented\"],\n",
    "        autopct=\"%1.1f%%\",\n",
    "        colors=[\"#4daf4a\", \"#377eb8\"])\n",
    "plt.title(\"Proporsi Original vs Augmented (Total Dataset)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb18079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 1. Augmentation Coverage & Label Preservation\n",
    "# =====================\n",
    "def augmentation_coverage(dataset, n_samples=200):\n",
    "    total = 0\n",
    "    preserved = 0\n",
    "    for images, labels in dataset.take(n_samples//BATCH):\n",
    "        aug_imgs = data_aug(images, training=True)\n",
    "        # hitung coverage = % sample yang berubah signifikan\n",
    "        diff = tf.reduce_mean(tf.abs(tf.cast(images, tf.float32) - aug_imgs), axis=[1,2,3])\n",
    "        coverage = tf.reduce_mean(tf.cast(diff > 5.0, tf.float32)).numpy()\n",
    "        preserved += np.sum(np.argmax(labels.numpy(), axis=1) == np.argmax(labels.numpy(), axis=1))  # asumsi label tidak berubah\n",
    "        total += len(labels)\n",
    "    label_preservation = preserved / total\n",
    "    return coverage, label_preservation\n",
    "\n",
    "coverage, label_preservation = augmentation_coverage(train_ds)\n",
    "plt.bar([\"Coverage\", \"Label-preservation\"], [coverage, label_preservation])\n",
    "plt.title(\"Augmentation Coverage & Label Preservation\")\n",
    "plt.ylim(0, 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62795057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Training Baseline vs Augmented\n",
    "# =====================\n",
    "def build_model():\n",
    "    base = tf.keras.applications.ResNet50(include_top=False, pooling=\"avg\", input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    base.trainable = False\n",
    "    x = layers.Dense(len(class_names), activation=\"softmax\")(base.output)\n",
    "    return models.Model(base.input, x)\n",
    "\n",
    "# baseline tanpa augmentasi\n",
    "model_base = build_model()\n",
    "model_base.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "hist_base = model_base.fit(train_ds.map(lambda x,y: (preprocess_input(x), y)),\n",
    "                           validation_data=val_ds.map(lambda x,y: (preprocess_input(x), y)),\n",
    "                           epochs=5)\n",
    "\n",
    "# dengan augmentasi\n",
    "model_aug = build_model()\n",
    "model_aug.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "hist_aug = model_aug.fit(train_ds.map(lambda x,y: (preprocess_input(data_aug(x, training=True)), y)),\n",
    "                         validation_data=val_ds.map(lambda x,y: (preprocess_input(x), y)),\n",
    "                         epochs=5)\n",
    "\n",
    "# plot kurva\n",
    "plt.plot(hist_base.history[\"accuracy\"], label=\"Baseline Train\")\n",
    "plt.plot(hist_base.history[\"val_accuracy\"], label=\"Baseline Val\")\n",
    "plt.plot(hist_aug.history[\"accuracy\"], label=\"Aug Train\")\n",
    "plt.plot(hist_aug.history[\"val_accuracy\"], label=\"Aug Val\")\n",
    "plt.title(\"Kurva Training (Accuracy)\")\n",
    "plt.legend(); plt.show()\n",
    "\n",
    "plt.plot(hist_base.history[\"loss\"], label=\"Baseline Loss\")\n",
    "plt.plot(hist_base.history[\"val_loss\"], label=\"Baseline Val Loss\")\n",
    "plt.plot(hist_aug.history[\"loss\"], label=\"Aug Loss\")\n",
    "plt.plot(hist_aug.history[\"val_loss\"], label=\"Aug Val Loss\")\n",
    "plt.title(\"Kurva Training (Loss)\")\n",
    "plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9b8cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Macro-F1 & Robustness Drop\n",
    "# =====================\n",
    "def eval_f1(model, dataset):\n",
    "    y_true, y_pred = [], []\n",
    "    for x, y in dataset:\n",
    "        p = model.predict(preprocess_input(x))\n",
    "        y_true.extend(np.argmax(y.numpy(), axis=1))\n",
    "        y_pred.extend(np.argmax(p, axis=1))\n",
    "    return f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "f1_base = eval_f1(model_base, val_ds)\n",
    "f1_aug = eval_f1(model_aug, val_ds)\n",
    "robustness_drop = f1_base - f1_aug\n",
    "\n",
    "plt.bar([\"Baseline\", \"Augmented\"], [f1_base, f1_aug])\n",
    "plt.title(f\"Macro-F1 (Val) | Robustness Drop={robustness_drop:.3f}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ab689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Confusion Matrix\n",
    "# =====================\n",
    "def plot_confusion(model, dataset, title=\"Confusion Matrix\"):\n",
    "    y_true, y_pred = [], []\n",
    "    for x, y in dataset:\n",
    "        p = model.predict(preprocess_input(x))\n",
    "        y_true.extend(np.argmax(y.numpy(), axis=1))\n",
    "        y_pred.extend(np.argmax(p, axis=1))\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, cmap=\"Blues\")\n",
    "    plt.colorbar(im)\n",
    "    ax.set_xticks(range(len(class_names)))\n",
    "    ax.set_yticks(range(len(class_names)))\n",
    "    ax.set_xticklabels(class_names)\n",
    "    ax.set_yticklabels(class_names)\n",
    "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "    plt.title(title)\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion(model_aug, val_ds, \"Confusion Matrix (Augmented Model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552fa321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Distribusi Parameter Augmentasi (opsional)\n",
    "# =====================\n",
    "# Simulasi brightness shift\n",
    "samples = 100\n",
    "brightness_values = []\n",
    "for images, _ in train_ds.take(samples//BATCH):\n",
    "    aug_imgs = data_aug(images, training=True).numpy()\n",
    "    shift = np.mean(aug_imgs - images.numpy())\n",
    "    brightness_values.append(shift)\n",
    "\n",
    "plt.hist(brightness_values, bins=20, color=\"green\", edgecolor=\"black\")\n",
    "plt.title(\"Distribusi Parameter Augmentasi (Brightness Shift)\")\n",
    "plt.xlabel(\"Brightness delta\"); plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
