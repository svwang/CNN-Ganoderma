{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aff4778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94851ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report,\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0441ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Konfigurasi \n",
    "# -----------------------\n",
    "IMG_SIZE = (224, 224)       \n",
    "BATCH_SIZE = 32     \n",
    "EPOCHS = 10\n",
    "ANNOTATION_JSON = \"augmented_output/annotations.json\"\n",
    "USE_COMBINED = True\n",
    "BASE_DIR = os.getcwd()\n",
    "DATASET_DIR = os.path.join(BASE_DIR, \"dataset_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77246b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Baca class names\n",
    "# -----------------------\n",
    "train_folder = os.path.join(DATASET_DIR, \"train\")\n",
    "class_names = sorted([d for d in os.listdir(train_folder) if os.path.isdir(os.path.join(train_folder, d))])\n",
    "num_classes = len(class_names)\n",
    "print(\"Detected classes:\", class_names)\n",
    "\n",
    "class_to_idx = {c: i for i, c in enumerate(class_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe441e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Load annotations.json\n",
    "# -----------------------\n",
    "image_paths = []\n",
    "labels_idx = []\n",
    "if os.path.exists(ANNOTATION_JSON):\n",
    "    with open(ANNOTATION_JSON, \"r\") as f:\n",
    "        ann = json.load(f)\n",
    "    for item in ann:\n",
    "        cls = item.get(\"class\")\n",
    "        if cls not in class_to_idx:\n",
    "            continue\n",
    "        idx = class_to_idx[cls]\n",
    "        orig = item.get(\"original\")\n",
    "        aug = item.get(\"augmented\")\n",
    "        if orig and os.path.exists(orig):\n",
    "            image_paths.append(orig); labels_idx.append(idx)\n",
    "        if aug and os.path.exists(aug):\n",
    "            image_paths.append(aug); labels_idx.append(idx)\n",
    "else:\n",
    "    print(f\"Warning: {ANNOTATION_JSON} tidak ditemukan.\")\n",
    "print(f\"Total images from annotations: {len(image_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca87c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Preprocess function (bisa dipanggil langsung oleh .map)\n",
    "# -----------------------\n",
    "def preprocess_path_label(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_image(image, channels=3, expand_animations=False)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)  # 0-1\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    return image, tf.one_hot(label, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc624cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Buat aug_ds (tanpa tf.py_function)\n",
    "# -----------------------\n",
    "if len(image_paths) > 0:\n",
    "    paths_tensor = tf.constant(image_paths)\n",
    "    labels_tensor = tf.constant(labels_idx, dtype=tf.int32)\n",
    "    aug_ds = tf.data.Dataset.from_tensor_slices((paths_tensor, labels_tensor))\n",
    "    # map langsung ke preprocess (tidak perlu py_function)\n",
    "    aug_ds = aug_ds.shuffle(len(image_paths), reshuffle_each_iteration=True)\n",
    "    aug_ds = aug_ds.map(lambda p, l: preprocess_path_label(p, l), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    aug_ds = aug_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "else:\n",
    "    aug_ds = tf.data.Dataset.from_tensor_slices(([],[]))  # kosong, kalau file tidak ditemukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed944130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Gabungkan dengan original\n",
    "# -----------------------\n",
    "if USE_COMBINED:\n",
    "    ds_original = tf.keras.utils.image_dataset_from_directory(\n",
    "        train_folder,\n",
    "        image_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        label_mode=\"categorical\",\n",
    "        shuffle=True\n",
    "    )\n",
    "    ds_original = ds_original.map(lambda x,y: (tf.cast(x, tf.float32)/255.0, y),\n",
    "                                  num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_ds = ds_original.concatenate(aug_ds).shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
    "else:\n",
    "    train_ds = aug_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c39fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Validasi & Test\n",
    "# -----------------------\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(DATASET_DIR, \"valid\"),\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(DATASET_DIR, \"test\"),\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "val_ds = val_ds.map(lambda x,y: (tf.cast(x, tf.float32)/255.0, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(lambda x,y: (tf.cast(x, tf.float32)/255.0, y), num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b307cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Build model (pastikan input pakai IMG_SIZE)\n",
    "# -----------------------\n",
    "def build_model(num_classes):\n",
    "    inputs = layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "    x = layers.Conv2D(32, (3,3), activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    x = layers.Conv2D(64, (3,3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    x = layers.Conv2D(128, (3,3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model(num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b063b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 7) Training\n",
    "# -----------------------\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "model.save(\"model_with_augmentations.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb0d857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 8) Plot: training curves\n",
    "# -----------------------\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.title(\"Training vs Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------\n",
    "# 9) Evaluasi di test set\n",
    "# -----------------------\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}  | Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# collect predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_prob = []\n",
    "\n",
    "start_time = time.time()\n",
    "for x, y in test_ds:\n",
    "    probs = model.predict(x)\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    y_true.extend(np.argmax(y.numpy(), axis=1))\n",
    "    y_pred.extend(preds)\n",
    "    y_prob.extend(probs)\n",
    "end_time = time.time()\n",
    "inference_time = (end_time - start_time) / max(1, len(y_true))\n",
    "print(f\"Rata-rata waktu inferensi per gambar: {inference_time:.4f} detik\")\n",
    "\n",
    "# -----------------------\n",
    "# 10) Confusion Matrix\n",
    "# -----------------------\n",
    "cm = confusion_matrix(y_true, y_pred, labels=range(num_classes))\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(cm, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.xticks(range(num_classes), class_names, rotation=45)\n",
    "plt.yticks(range(num_classes), class_names)\n",
    "for i in range(num_classes):\n",
    "    for j in range(num_classes):\n",
    "        plt.text(j, i, cm[i,j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------\n",
    "# 11) Classification report + per-class metrics\n",
    "# -----------------------\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "report_dict = classification_report(y_true, y_pred, target_names=class_names, output_dict=True, zero_division=0)\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "precision_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "recall_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "print(f\"Accuracy: {acc:.4f} | Precision(macro): {precision_macro:.4f} | Recall(macro): {recall_macro:.4f} | F1(macro): {f1_macro:.4f}\")\n",
    "\n",
    "# -----------------------\n",
    "# 12) ROC AUC (One-vs-Rest) - multi-class\n",
    "# -----------------------\n",
    "y_prob_arr = np.array(y_prob)\n",
    "y_true_bin = label_binarize(y_true, classes=list(range(num_classes)))\n",
    "\n",
    "# Pastikan y_true_bin dan y_prob_arr punya kolom sesuai num_classes\n",
    "if num_classes == 2:\n",
    "    # jika y_prob_arr shape (N,1), ubah jadi (N,2)\n",
    "    if y_prob_arr.shape[1] == 1:\n",
    "        y_prob_arr = np.hstack([1 - y_prob_arr, y_prob_arr])\n",
    "    # jika y_true_bin shape (N,1), tambahkan kolom lain\n",
    "    if y_true_bin.shape[1] == 1:\n",
    "        y_true_bin = np.hstack([1 - y_true_bin, y_true_bin])\n",
    "\n",
    "# compute AUC per class\n",
    "auc_per_class = {}\n",
    "for c in range(num_classes):\n",
    "    try:\n",
    "        auc_score = roc_auc_score(y_true_bin[:, c], y_prob_arr[:, c])\n",
    "    except ValueError:\n",
    "        auc_score = np.nan\n",
    "    auc_per_class[class_names[c]] = auc_score\n",
    "\n",
    "print(\"\\nAUC per class (One-vs-Rest):\")\n",
    "for k, v in auc_per_class.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# ROC curve / AUC plotting\n",
    "plt.figure(figsize=(6,6))\n",
    "if num_classes == 2:\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    y_score = y_prob_arr[:, 1]  # kolom kelas positif\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin[:, 1], y_score)\n",
    "    auc_score = roc_auc_score(y_true_bin[:, 1], y_score)\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {auc_score:.4f}\")\n",
    "    plt.plot([0,1], [0,1], 'k--')\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend()\n",
    "else:\n",
    "    # multi-class: tampilkan bar chart AUC per class\n",
    "    plt.bar(list(auc_per_class.keys()), [0 if np.isnan(v) else v for v in auc_per_class.values()])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0,1)\n",
    "    plt.title(\"AUC per Class (One-vs-Rest)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 13) Bar chart: precision/recall/f1 per class\n",
    "# -----------------------\n",
    "precisions = [report_dict[c]['precision'] for c in class_names]\n",
    "recalls = [report_dict[c]['recall'] for c in class_names]\n",
    "f1s = [report_dict[c]['f1-score'] for c in class_names]\n",
    "\n",
    "x = np.arange(len(class_names))\n",
    "width = 0.25\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(x - width, precisions, width, label='Precision')\n",
    "plt.bar(x, recalls, width, label='Recall')\n",
    "plt.bar(x + width, f1s, width, label='F1-Score')\n",
    "plt.xticks(x, class_names, rotation=45)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0,1)\n",
    "plt.title(\"Per-Class Precision / Recall / F1\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
